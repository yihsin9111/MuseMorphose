{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preparing data] now at #0\n",
      "[preparing data] now at #200\n",
      "[preparing data] now at #400\n",
      "[preparing data] now at #600\n",
      "[preparing data] now at #800\n",
      "[preparing data] now at #1000\n",
      "[preparing data] now at #1200\n",
      "[preparing data] now at #1400\n",
      "[preparing data] now at #1600\n",
      "[sampled pieces] [930]\n",
      "/home/yihsin/miniforge3/envs/cne/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yihsin/MidiStyleTransfer/MuseMorphose/generate.py\", line 224, in <module>\n",
      "    ).to(device)\n",
      "  File \"/home/yihsin/miniforge3/envs/cne/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1343, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/yihsin/miniforge3/envs/cne/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/yihsin/miniforge3/envs/cne/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/yihsin/miniforge3/envs/cne/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/home/yihsin/miniforge3/envs/cne/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 930, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/yihsin/miniforge3/envs/cne/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1329, in convert\n",
      "    return t.to(\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 generate.py config/skyline.yaml ./ckpt/enc_dec_12L-16_bars-seqlen_1280/params/step_8100-RC_1.565-KL_3.176-model.pt generations/ 1 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenizer utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# define miditok tokenizer config\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from symusic import Score\n",
    "\n",
    "BEAT_RES = {(0, 1): 24, (1, 2): 8, (2, 4): 4, (4, 8): 2}\n",
    "TOKENIZER_PARAMS = {\n",
    "    \"pitch_range\": (21, 109),\n",
    "    \"beat_res\": BEAT_RES,\n",
    "    \"num_velocities\": 24,\n",
    "    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\"],\n",
    "    \"use_chords\": True,\n",
    "    \"use_rests\": True,\n",
    "    \"use_tempos\": True,\n",
    "    \"use_time_signatures\": True,\n",
    "    \"use_programs\": False,  # no multitrack here\n",
    "    \"num_tempos\": 32,\n",
    "    \"tempo_range\": (50, 200),  # (min_tempo, max_tempo)\n",
    "}\n",
    "\n",
    "# Creating a multitrack tokenizer, read the doc to explore all the parameters\n",
    "config = TokenizerConfig(**TOKENIZER_PARAMS)\n",
    "tokenizer = REMI(config)\n",
    "\n",
    "\n",
    "def gnpy2midi(npy_path, midi_path=\"/content/test_from_npy.mid\"):\n",
    "  tokens = np.load(npy_path, allow_pickle=True)\n",
    "  tokens = np.array([t for t in tokens if t<600])\n",
    "  tokens = tokens.reshape(1, -1)\n",
    "  #tokens = np.array([event2idx[int(e)] for e in tokens]).reshape(1,-1)\n",
    "  converted_back_midi = tokenizer(tokens)\n",
    "  print(converted_back_midi)\n",
    "  converted_back_midi.dump_midi(midi_path) # Save the MIDI file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = np.load(\"generations/id223_bar0_orig_orig.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def read_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "dict_path = \"pickles/skyline_miditok_vocab.pkl\"\n",
    "tokenizer_vocab = read_pickle(dict_path)\n",
    "event2idx = tokenizer_vocab[0]                     # [{\"event\":idx}]\n",
    "idx2event = [k for k, v in event2idx.items()]   # [event]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### start converting generated result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(ttype=Tick, tpq=48, begin=0, end=2526, tracks=1, notes=328, time_sig=1, key_sig=0, markers=0)\n"
     ]
    }
   ],
   "source": [
    "gnpy2midi(\"generations/id1537_bar0_orig_orig.npy\", \"generations/sample01.mid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
