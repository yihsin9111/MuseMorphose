{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataloader output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import REMISkylineToMidiVAEDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "def numpy_to_tensor(arr, use_gpu=True, device='cuda:0'):\n",
    "  if use_gpu:\n",
    "    return torch.tensor(arr).to(device).float()\n",
    "  else:\n",
    "    return torch.tensor(arr).float()\n",
    "\n",
    "def tensor_to_numpy(tensor):\n",
    "  return tensor.cpu().detach().numpy()\n",
    "\n",
    "def pickle_load(f):\n",
    "  return pickle.load(open(f, 'rb'))\n",
    "\n",
    "def pickle_dump(obj, f):\n",
    "  pickle.dump(obj, open(f, 'wb'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "config_path = \"/home/yihsin/MidiStyleTransfer/MuseMorphose/config/skyline.yaml\"\n",
    "config = yaml.load(open(config_path, 'r'), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preparing data] now at #0\n",
      "[preparing data] now at #200\n",
      "[preparing data] now at #400\n",
      "[preparing data] now at #600\n",
      "[preparing data] now at #800\n",
      "[preparing data] now at #1000\n",
      "[preparing data] now at #1200\n",
      "[preparing data] now at #1400\n",
      "[preparing data] now at #1600\n",
      "[preparing data] now at #1800\n",
      "[preparing data] now at #2000\n",
      "[preparing data] now at #2200\n",
      "[preparing data] now at #2400\n",
      "[preparing data] now at #2600\n",
      "[preparing data] now at #2800\n",
      "[preparing data] now at #3000\n",
      "[preparing data] now at #3200\n",
      "[preparing data] now at #3400\n",
      "[preparing data] now at #3600\n",
      "[preparing data] now at #3800\n",
      "[preparing data] now at #4000\n",
      "[preparing data] now at #4200\n",
      "[preparing data] now at #4400\n",
      "[preparing data] now at #4600\n",
      "[preparing data] now at #4800\n",
      "[preparing data] now at #5000\n",
      "[preparing data] now at #5200\n",
      "[preparing data] now at #5400\n",
      "[preparing data] now at #5600\n"
     ]
    }
   ],
   "source": [
    "dset = REMISkylineToMidiVAEDataset(\n",
    "    config['data']['data_dir'], config['data']['vocab_path'], \n",
    "    do_augment=True, use_composer_cls = False,\n",
    "    model_enc_seqlen=config['data']['enc_seqlen'], \n",
    "    model_dec_seqlen=config['data']['dec_seqlen'], \n",
    "    model_max_bars=config['data']['max_bars'],\n",
    "    pieces=pickle_load(config['data']['train_split']),\n",
    "    pad_to_same=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dloader = DataLoader(dset, batch_size=config['data']['batch_size'], shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preparing data] now at #0\n",
      "[preparing data] now at #200\n",
      "[preparing data] now at #400\n",
      "[preparing data] now at #600\n",
      "[preparing data] now at #800\n",
      "[preparing data] now at #1000\n",
      "[preparing data] now at #1200\n",
      "[preparing data] now at #1400\n",
      "[preparing data] now at #1600\n"
     ]
    }
   ],
   "source": [
    "dset_val = REMISkylineToMidiVAEDataset(\n",
    "    config['data']['data_dir'], config['data']['vocab_path'], \n",
    "    do_augment=False, use_composer_cls = False,\n",
    "    model_enc_seqlen=config['data']['enc_seqlen'], \n",
    "    model_dec_seqlen=config['data']['dec_seqlen'], \n",
    "    model_max_bars=config['data']['max_bars'],\n",
    "    pieces=pickle_load(config['data']['val_split']),\n",
    "    pad_to_same=True\n",
    ")\n",
    "dloader_val = DataLoader(dset_val, batch_size=config['data']['batch_size'], shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./model')\n",
    "from model.musemorphose import MuseMorphose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yihsin/miniforge3/envs/muse/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mconf = config['model']\n",
    "model = MuseMorphose(\n",
    "  mconf['enc_n_layer'], mconf['enc_n_head'], mconf['enc_d_model'], mconf['enc_d_ff'],\n",
    "  mconf['dec_n_layer'], mconf['dec_n_head'], mconf['dec_d_model'], mconf['dec_d_ff'],\n",
    "  mconf['d_latent'], mconf['d_embed'], dset.vocab_size,\n",
    "  d_polyph_emb=mconf['d_polyph_emb'], d_rfreq_emb=mconf['d_rfreq_emb'],\n",
    "  cond_mode=mconf['cond_mode'], use_attr_cls=False\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### start testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "max_lr, min_lr = config['training']['max_lr'], config['training']['min_lr']\n",
    "\n",
    "lr_decay_steps = config['training']['lr_decay_steps']\n",
    "lr_warmup_steps = config['training']['lr_warmup_steps']\n",
    "no_kl_steps = config['training']['no_kl_steps']\n",
    "kl_cycle_steps = config['training']['kl_cycle_steps']\n",
    "kl_max_beta = config['training']['kl_max_beta']\n",
    "free_bit_lambda = config['training']['free_bit_lambda']\n",
    "max_lr, min_lr = config['training']['max_lr'], config['training']['min_lr']\n",
    "\n",
    "opt_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(opt_params, lr=max_lr)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, lr_decay_steps, eta_min=min_lr\n",
    "  )\n",
    "\n",
    "import time\n",
    "epoch = 0\n",
    "optim = optimizer\n",
    "sched = scheduler\n",
    "\n",
    "model.train()\n",
    "print ('[epoch {:03d}] training ...'.format(epoch))\n",
    "print ('[epoch {:03d}] # batches = {}'.format(epoch, len(dloader)))\n",
    "st = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch_samples in enumerate(dloader):\n",
    "        model.zero_grad()\n",
    "        batch_enc_inp = batch_samples['enc_input'].permute(2, 0, 1).to(device)\n",
    "        batch_dec_inp = batch_samples['dec_input'].permute(1, 0).to(device)\n",
    "        batch_dec_tgt = batch_samples['dec_target'].permute(1, 0).to(device)\n",
    "        batch_inp_bar_pos = batch_samples['bar_pos'].to(device)\n",
    "        batch_inp_lens = batch_samples['length']\n",
    "        batch_padding_mask = batch_samples['enc_padding_mask'].to(device)\n",
    "        batch_composer_cls = batch_samples['composer_cls'].permute(1, 0).to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, logvar, dec_logits = model(\n",
    "      batch_enc_inp, batch_dec_inp, \n",
    "      batch_inp_bar_pos, batch_composer_cls,\n",
    "      padding_mask=batch_padding_mask\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_beta = kl_max_beta\n",
    "losses = model.compute_loss(mu, logvar, kl_beta, free_bit_lambda, dec_logits, batch_dec_tgt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
